{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca502718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix \n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfff4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b2004bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92e5c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc77ecf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: keyword, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ff7c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f72af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['location'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b43451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['keyword'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd52ac03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['keyword'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7ffae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb4aee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping records that have both keyword and location as null\n",
    "#mask = (data['keyword'].isnull()) & (data['location'].isnull())\n",
    "#data = data.drop(data[mask].index, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729e9e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba33de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab876a",
   "metadata": {},
   "source": [
    "###### Replacing null locations with mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e43d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_of_location = data.pivot_table(values='location', columns = 'keyword', aggfunc=(lambda x: x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc10059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode_of_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264b1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_values = data['location'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971ea380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e72750d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[missing_values, 'location'] = data.loc[missing_values, 'keyword'].apply(lambda x: mode_of_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56314bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d25ec5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1                   Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4                              Forest fire near La Ronge Sask. Canada   \n",
       "2   5                   All residents asked to 'shelter in place' are ...   \n",
       "3   6                   13,000 people receive #wildfires evacuation or...   \n",
       "4   7                   Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d259c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping ID column\n",
    "data = data.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeed76b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target\n",
       "0                   Our Deeds are the Reason of this #earthquake M...       1\n",
       "1                              Forest fire near La Ronge Sask. Canada       1\n",
       "2                   All residents asked to 'shelter in place' are ...       1\n",
       "3                   13,000 people receive #wildfires evacuation or...       1\n",
       "4                   Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d328fa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword     object\n",
       "location    object\n",
       "text        object\n",
       "target       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08989a57",
   "metadata": {},
   "source": [
    "###### Creating new column to combine keyword and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "321748e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['keyword']+'' + data['location'] + '' + data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f3733d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  target  \\\n",
       "0                   Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                              Forest fire near La Ronge Sask. Canada       1   \n",
       "2                   All residents asked to 'shelter in place' are ...       1   \n",
       "3                   13,000 people receive #wildfires evacuation or...       1   \n",
       "4                   Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                             content  \n",
       "0  Our Deeds are the Reason of this #earthquake M...  \n",
       "1             Forest fire near La Ronge Sask. Canada  \n",
       "2  All residents asked to 'shelter in place' are ...  \n",
       "3  13,000 people receive #wildfires evacuation or...  \n",
       "4  Just got sent this photo from Ruby #Alaska as ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9fa204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cf7ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns = 'target', axis = 1)\n",
    "Y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91683f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fcaa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8317cf1d",
   "metadata": {},
   "source": [
    "###### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07487d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['location'] = data['location'].astype(str)\n",
    "#data['keyword'] = data['keyword'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad90725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8ad9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['location'] = encoder.fit_transform(data['location'])\n",
    "#data['keyword'] = encoder.fit_transform(data['keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ded4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7490daba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a36483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e69fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3df821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e4d6de",
   "metadata": {},
   "source": [
    "###### Stemming and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fec2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1384ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def stemming(content):\\n    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) #this regex is looking for words from a-z only. no numbers. commas and fullstops are replaced with a space as indicated by ' '\\n    stemmed_content = stemmed_content.lower()#convert everything to lowercase letters\\n    stemmed_content = stemmed_content.split()#convert everything in content to a list\\n    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #reducing words to their root word - but for loop is removing all stop words\\n    stemmed_content = ' '.join(stemmed_content)#joining all words\\n    return stemmed_content\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) #this regex is looking for words from a-z only. no numbers. commas and fullstops are replaced with a space as indicated by ' '\n",
    "    stemmed_content = stemmed_content.lower()#convert everything to lowercase letters\n",
    "    stemmed_content = stemmed_content.split()#convert everything in content to a list\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #reducing words to their root word - but for loop is removing all stop words\n",
    "    stemmed_content = ' '.join(stemmed_content)#joining all words\n",
    "    return stemmed_content'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e4a290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    snowball_stem = SnowballStemmer(language='english')\n",
    "    stemmed_content = [snowball_stem.stem(word) for word in stemmed_content if word not in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93947b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e16b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               deed reason earthquak may allah forgiv us\n",
      "1                    forest fire near la rong sask canada\n",
      "2       resid ask shelter place notifi offic evacu she...\n",
      "3             peopl receiv wildfir evacu order california\n",
      "4       got sent photo rubi alaska smoke wildfir pour ...\n",
      "                              ...                        \n",
      "7608    two giant crane hold bridg collaps nearbi home...\n",
      "7609    aria ahrari thetawniest control wild fire cali...\n",
      "7610             utc km volcano hawaii http co zdtoyd ebj\n",
      "7611    polic investig e bike collid car littl portug ...\n",
      "7612    latest home raze northern california wildfir a...\n",
      "Name: content, Length: 7613, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19e20748",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['content'].values\n",
    "Y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9910e3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deed reason earthquak may allah forgiv us'\n",
      " 'forest fire near la rong sask canada'\n",
      " 'resid ask shelter place notifi offic evacu shelter place order expect'\n",
      " ... 'utc km volcano hawaii http co zdtoyd ebj'\n",
      " 'polic investig e bike collid car littl portug e bike rider suffer serious non life threaten injuri'\n",
      " 'latest home raze northern california wildfir abc news http co ymi rskq'] [1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "739fe417",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer() \n",
    "vectorizer.fit(X) \n",
    "X = vectorizer.transform(X) #convert all values to respective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef71cf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 26490) (7613,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0d69a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 23830)\t0.27583297987492594\n",
      "  (0, 18710)\t0.35176551667005757\n",
      "  (0, 14357)\t0.2944679025040954\n",
      "  (0, 9096)\t0.4601979122885903\n",
      "  (0, 7023)\t0.3264721804901336\n",
      "  (0, 5620)\t0.47567957863899146\n",
      "  (0, 534)\t0.41088754939408534\n",
      "  (1, 19804)\t0.4856420874212593\n",
      "  (1, 19387)\t0.5079192668223127\n",
      "  (1, 15571)\t0.30456128004141125\n",
      "  (1, 13204)\t0.36099543042535365\n",
      "  (1, 9088)\t0.314986937624406\n",
      "  (1, 8588)\t0.22839510059028587\n",
      "  (1, 3406)\t0.36292342770853014\n",
      "  (2, 20301)\t0.5906727775065879\n",
      "  (2, 18991)\t0.2849063437754631\n",
      "  (2, 17499)\t0.46075066109361407\n",
      "  (2, 16676)\t0.22393341828405666\n",
      "  (2, 16372)\t0.22070858653868422\n",
      "  (2, 15960)\t0.3351670792316749\n",
      "  (2, 7899)\t0.23464560831925124\n",
      "  (2, 7728)\t0.18612546903991178\n",
      "  (2, 1196)\t0.238214598136075\n",
      "  (3, 24971)\t0.38031879021445264\n",
      "  (3, 18726)\t0.5701174302881474\n",
      "  :\t:\n",
      "  (7611, 21570)\t0.2522971328474761\n",
      "  (7611, 20161)\t0.2436098288009067\n",
      "  (7611, 19159)\t0.27164163500085636\n",
      "  (7611, 17727)\t0.2956019796087512\n",
      "  (7611, 17650)\t0.17920308086689077\n",
      "  (7611, 15897)\t0.24991222380841727\n",
      "  (7611, 13704)\t0.20693816876134943\n",
      "  (7611, 13598)\t0.18721587628646238\n",
      "  (7611, 11875)\t0.21117622089435722\n",
      "  (7611, 11689)\t0.19119353193127903\n",
      "  (7611, 4400)\t0.19427802650016335\n",
      "  (7611, 3496)\t0.18072612325744403\n",
      "  (7611, 2119)\t0.5757769430325739\n",
      "  (7612, 25967)\t0.42969947320972485\n",
      "  (7612, 24971)\t0.2700818239937659\n",
      "  (7612, 19484)\t0.4494104754090209\n",
      "  (7612, 18599)\t0.3075679736324871\n",
      "  (7612, 15931)\t0.2772727115718967\n",
      "  (7612, 15658)\t0.22505417732478014\n",
      "  (7612, 13332)\t0.28656053959139716\n",
      "  (7612, 11103)\t0.08523032764061683\n",
      "  (7612, 10900)\t0.24218748445108604\n",
      "  (7612, 4244)\t0.08011247214803752\n",
      "  (7612, 3344)\t0.2507776301347225\n",
      "  (7612, 26)\t0.3177631834415697\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae0f9d",
   "metadata": {},
   "source": [
    "###### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "09d2b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a55ea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 26490) (6090, 26490) (1523, 26490)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71346e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10f907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e820e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69cfe619",
   "metadata": {},
   "source": [
    "###### NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f109f3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(26490,)),        \n",
    "    Dense(300, activation='relu'),       \n",
    "    BatchNormalization(),                \n",
    "    Dropout(0.5),                       \n",
    "    Dense(2, activation='sigmoid')      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "529bf2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look into optimizers, loss (one hot encoding label encoding)\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11187c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba56d2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - accuracy: 0.6993 - loss: 0.5747 - val_accuracy: 0.6059 - val_loss: 0.6307\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9209 - loss: 0.2123 - val_accuracy: 0.7488 - val_loss: 0.5396\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9630 - loss: 0.1118 - val_accuracy: 0.7685 - val_loss: 0.4814\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9769 - loss: 0.0745 - val_accuracy: 0.7750 - val_loss: 0.6067\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9850 - loss: 0.0516 - val_accuracy: 0.7849 - val_loss: 0.7536\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - accuracy: 0.9887 - loss: 0.0393 - val_accuracy: 0.7915 - val_loss: 0.7815\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_split= .1, epochs = 10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309179b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7c059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe1b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665ca22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31298343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad05ddfe",
   "metadata": {},
   "source": [
    "###### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d815a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2ed2b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best parameters found:  {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best score found:  0.7893267651888342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid_random = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid_random, n_iter=30, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Perform random search\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get best hyperparameters from random search\n",
    "best_params_random = random_search.best_params_\n",
    "\n",
    "# Define the parameter grid for GridSearchCV using the best parameters from random search\n",
    "param_grid_grid = {\n",
    "    'n_estimators': [best_params_random['n_estimators']],\n",
    "    'max_depth': [best_params_random['max_depth']],\n",
    "    'min_samples_split': [best_params_random['min_samples_split'] - 1, \n",
    "                          best_params_random['min_samples_split'], \n",
    "                          best_params_random['min_samples_split'] + 1],\n",
    "    'min_samples_leaf': [best_params_random['min_samples_leaf'] - 1, \n",
    "                         best_params_random['min_samples_leaf'], \n",
    "                         best_params_random['min_samples_leaf'] + 1],\n",
    "    'max_features': [best_params_random['max_features']]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_grid, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best score found: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1fc8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8958949096880131\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score\n",
    "X_train_prediction = grid_search.predict(X_train)\n",
    "train_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
    "print('Accuracy:', train_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cfc0e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7925147734734077\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score\n",
    "X_test_prediction = grid_search.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
    "print('Accuracy:', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816f404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17370f2d",
   "metadata": {},
   "source": [
    "###### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3489ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 18 is smaller than n_iter=30. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Parameters (Fine Search): {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "XGBoost Best Parameters (Fine Search): {'colsample_bytree': 0.5, 'learning_rate': 0.2, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1.0}\n",
      "SVM Best Parameters (Fine Search): {'C': 0.010000000000000002, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Best Model Train Accuracy (Fine Search): 0.8973727422003284\n",
      "Best Model Test Accuracy (Fine Search): 0.7872619829284307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "is_sparse = isinstance(X_train, csr_matrix)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=not is_sparse)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define parameter grids for randomized search (coarse search)\n",
    "logistic_param_grid_coarse = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "xgboost_param_grid_coarse = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "svm_param_grid_coarse = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for each model (coarse search)\n",
    "logistic_random_search_coarse = RandomizedSearchCV(LogisticRegression(), logistic_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "xgboost_random_search_coarse = RandomizedSearchCV(XGBClassifier(objective='binary:logistic'), xgboost_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "svm_random_search_coarse = RandomizedSearchCV(svm.SVC(), svm_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using RandomizedSearchCV (coarse search)\n",
    "logistic_random_search_coarse.fit(X_train_scaled, Y_train)\n",
    "xgboost_random_search_coarse.fit(X_train_scaled, Y_train)\n",
    "svm_random_search_coarse.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Get best hyperparameters from RandomizedSearchCV (coarse search)\n",
    "best_logistic_params_coarse = logistic_random_search_coarse.best_params_\n",
    "best_xgboost_params_coarse = xgboost_random_search_coarse.best_params_\n",
    "best_svm_params_coarse = svm_random_search_coarse.best_params_\n",
    "\n",
    "# Define parameter grids for GridSearchCV (fine search)\n",
    "logistic_param_grid_fine = {\n",
    "    'penalty': [best_logistic_params_coarse['penalty']],\n",
    "    'C': [best_logistic_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'solver': [best_logistic_params_coarse['solver']]\n",
    "}\n",
    "\n",
    "xgboost_param_grid_fine = {\n",
    "    'learning_rate': [best_xgboost_params_coarse['learning_rate'] * i for i in [0.5, 1, 2]],\n",
    "    'n_estimators': [best_xgboost_params_coarse['n_estimators']],\n",
    "    'max_depth': [best_xgboost_params_coarse['max_depth']],\n",
    "    'min_child_weight': [best_xgboost_params_coarse['min_child_weight']],\n",
    "    'subsample': [best_xgboost_params_coarse['subsample']],\n",
    "    'colsample_bytree': [best_xgboost_params_coarse['colsample_bytree']]\n",
    "}\n",
    "\n",
    "svm_param_grid_fine = {\n",
    "    'C': [best_svm_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'gamma': [best_svm_params_coarse['gamma'] * i for i in [0.1, 1, 10]],\n",
    "    'kernel': [best_svm_params_coarse['kernel']]\n",
    "}\n",
    "\n",
    "# GridSearchCV for each model (fine search)\n",
    "logistic_grid_search_fine = GridSearchCV(LogisticRegression(), param_grid=logistic_param_grid_fine, cv=5, n_jobs=-1)\n",
    "xgboost_grid_search_fine = GridSearchCV(XGBClassifier(objective='binary:logistic'), param_grid=xgboost_param_grid_fine, cv=5, n_jobs=-1)\n",
    "svm_grid_search_fine = GridSearchCV(svm.SVC(), param_grid=svm_param_grid_fine, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using GridSearchCV (fine search)\n",
    "logistic_grid_search_fine.fit(X_train_scaled, Y_train)\n",
    "xgboost_grid_search_fine.fit(X_train_scaled, Y_train)\n",
    "svm_grid_search_fine.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Print best hyperparameters from GridSearchCV (fine search)\n",
    "print(\"Logistic Regression Best Parameters (Fine Search):\", logistic_grid_search_fine.best_params_)\n",
    "print(\"XGBoost Best Parameters (Fine Search):\", xgboost_grid_search_fine.best_params_)\n",
    "print(\"SVM Best Parameters (Fine Search):\", svm_grid_search_fine.best_params_)\n",
    "\n",
    "# Compare cross-validated scores of each model\n",
    "logistic_cv_score_fine = logistic_grid_search_fine.best_score_\n",
    "xgboost_cv_score_fine = xgboost_grid_search_fine.best_score_\n",
    "svm_cv_score_fine = svm_grid_search_fine.best_score_\n",
    "\n",
    "# Select the best model based on cross-validated scores\n",
    "best_model_fine = None\n",
    "if logistic_cv_score_fine >= xgboost_cv_score_fine and logistic_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = logistic_grid_search_fine.best_estimator_\n",
    "elif xgboost_cv_score_fine >= logistic_cv_score_fine and xgboost_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = xgboost_grid_search_fine.best_estimator_\n",
    "else:\n",
    "    best_model_fine = svm_grid_search_fine.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_accuracy_fine = best_model_fine.score(X_train_scaled, Y_train)\n",
    "print(\"Best Model Train Accuracy (Fine Search):\", train_accuracy_fine)\n",
    "test_accuracy_fine = best_model_fine.score(X_test_scaled, Y_test)\n",
    "print(\"Best Model Test Accuracy (Fine Search):\", test_accuracy_fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8a9f99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[1]\n",
      "This is real tweet\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[70]\n",
    "print(Y_test[70])\n",
    "prediction = best_model_fine.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('This is fake tweet')\n",
    "else:\n",
    "    print('This is real tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a74fac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd9e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc597ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
