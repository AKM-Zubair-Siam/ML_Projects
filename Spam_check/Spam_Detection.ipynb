{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd85ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix#sadness (0), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824691b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv('mail_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e6fccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73faeb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6083cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    0\n",
       "Message     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f8eda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data.replace({'Category':{'ham':0,'spam':1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1f16703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6e9d32",
   "metadata": {},
   "source": [
    "##### Splitting labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2972f9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Message\n",
      "0     Go until jurong point, crazy.. Available only ...\n",
      "1                         Ok lar... Joking wif u oni...\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     U dun say so early hor... U c already then say...\n",
      "4     Nah I don't think he goes to usf, he lives aro...\n",
      "...                                                 ...\n",
      "5567  This is the 2nd time we have tried 2 contact u...\n",
      "5568               Will Ã¼ b going to esplanade fr home?\n",
      "5569  Pity, * was in mood for that. So...any other s...\n",
      "5570  The guy did some bitching but I acted like i'd...\n",
      "5571                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 1 columns] 0       0\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "5567    1\n",
      "5568    0\n",
      "5569    0\n",
      "5570    0\n",
      "5571    0\n",
      "Name: Category, Length: 5572, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = spam_data.drop(columns='Category', axis = 1)\n",
    "Y = spam_data['Category']\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a067e6",
   "metadata": {},
   "source": [
    "##### Stemming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1baa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(Message):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', Message) #this regex is looking for words from a-z only. no numbers. commas and fullstops are replaced with a space as indicated by ' '\n",
    "    stemmed_content = re.sub(r'http\\S+', '', Message) #checks for hyperlinks\n",
    "    stemmed_content = stemmed_content.lower()#convert everything to lowercase letters\n",
    "    stemmed_content = stemmed_content.split()#convert everything in text to a list\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #reducing words to their root word - but for loop is removing all stop words\n",
    "    stemmed_content = ' '.join(stemmed_content)#joining all words\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1347c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data['Message'] = spam_data['Message'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a1adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go jurong point, crazy.. avail bugi n great world la e buffet... cine got amor wat...'\n",
      " 'ok lar... joke wif u oni...'\n",
      " \"free entri 2 wkli comp win fa cup final tkt 21st may 2005. text fa 87121 receiv entri question(std txt rate)t&c' appli 08452810075over18'\"\n",
      " ... 'pity, * mood that. so...ani suggestions?'\n",
      " \"guy bitch act like i'd interest buy someth els next week gave us free\"\n",
      " 'rofl. true name'] [0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = spam_data['Message'].values\n",
    "Y = spam_data['Category'].values\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81be1711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting text data to numbers\n",
    "#main point of vectorizer is that it will create feature columns that it deems is important\n",
    "vectorizer = TfidfVectorizer() #basically finds words that are repeating the most to assign a value to it. similarly its inversely doing the opposite where if certain words are showing up and it doesnt have a value, it doesnt provide it value\n",
    "vectorizer.fit(X) #only fitting X bc Y already is all numbers (0,1)\n",
    "\n",
    "X = vectorizer.transform(X) #convert all values to respective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab26c123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8050)\t0.22962269749428962\n",
      "  (0, 7842)\t0.1892146376670875\n",
      "  (0, 5648)\t0.25827574458086533\n",
      "  (0, 4277)\t0.28937206929337134\n",
      "  (0, 4160)\t0.34253158750893153\n",
      "  (0, 3480)\t0.1892146376670875\n",
      "  (0, 3442)\t0.16058011098012456\n",
      "  (0, 3397)\t0.13794804480121792\n",
      "  (0, 2250)\t0.30739505718901877\n",
      "  (0, 1990)\t0.28937206929337134\n",
      "  (0, 1713)\t0.30040366604489843\n",
      "  (0, 1711)\t0.32698342515267853\n",
      "  (0, 1293)\t0.26526713572498567\n",
      "  (0, 1066)\t0.34253158750893153\n",
      "  (1, 7959)\t0.43651585199297055\n",
      "  (1, 5275)\t0.556006883677782\n",
      "  (1, 5245)\t0.2765613566485246\n",
      "  (1, 4314)\t0.41533459133332773\n",
      "  (1, 4124)\t0.5013195084100336\n",
      "  (2, 8009)\t0.1912428307935117\n",
      "  (2, 7971)\t0.14602126349253328\n",
      "  (2, 7522)\t0.12364246685411001\n",
      "  (2, 7343)\t0.22161471585273418\n",
      "  (2, 7198)\t0.11922152476490841\n",
      "  (2, 6858)\t0.19741178626772932\n",
      "  :\t:\n",
      "  (5568, 3397)\t0.2900009528925707\n",
      "  (5568, 3200)\t0.5576572124830113\n",
      "  (5568, 2859)\t0.6874001368485954\n",
      "  (5569, 7224)\t0.25114395890631247\n",
      "  (5569, 6987)\t0.4874939876356764\n",
      "  (5569, 6673)\t0.3253834421202834\n",
      "  (5569, 5583)\t0.4874939876356764\n",
      "  (5569, 4880)\t0.4054088745597105\n",
      "  (5569, 1089)\t0.43748736663495047\n",
      "  (5570, 7881)\t0.2189176354737293\n",
      "  (5570, 7651)\t0.24528799717414687\n",
      "  (5570, 6698)\t0.2567559951835328\n",
      "  (5570, 5075)\t0.2495330867943526\n",
      "  (5570, 4407)\t0.18774319632401437\n",
      "  (5570, 3976)\t0.34145087281017855\n",
      "  (5570, 3530)\t0.2510414855289603\n",
      "  (5570, 3318)\t0.32704155107753746\n",
      "  (5570, 3213)\t0.18987517734733508\n",
      "  (5570, 2773)\t0.3161295053804294\n",
      "  (5570, 1743)\t0.24395708441060104\n",
      "  (5570, 1524)\t0.34749287078261926\n",
      "  (5570, 908)\t0.35446784555567207\n",
      "  (5571, 7477)\t0.5286113464416391\n",
      "  (5571, 6177)\t0.6959354280162229\n",
      "  (5571, 4989)\t0.48604930248384676\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43123e2e",
   "metadata": {},
   "source": [
    "##### Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58d0d779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8050)\t10.610294654784285\n",
      "  (0, 7842)\t3.8773009678473875\n",
      "  (0, 5648)\t11.786587357750989\n",
      "  (0, 4277)\t20.196702346052152\n",
      "  (0, 4160)\t74.65252962559933\n",
      "  (0, 3480)\t4.384491807051848\n",
      "  (0, 3442)\t3.2345142595031966\n",
      "  (0, 3397)\t2.324027425051536\n",
      "  (0, 2250)\t32.20026757080644\n",
      "  (0, 1990)\t28.707498530069987\n",
      "  (0, 1713)\t24.380954375790882\n",
      "  (0, 1711)\t37.422578295735015\n",
      "  (0, 1293)\t15.002187984133633\n",
      "  (0, 1066)\t74.65252962559933\n",
      "  (1, 7959)\t18.37311842570421\n",
      "  (1, 5275)\t44.52172833850037\n",
      "  (1, 5245)\t3.0468679928408937\n",
      "  (1, 4314)\t14.129169916144727\n",
      "  (1, 4124)\t33.69351581745086\n",
      "  (2, 8009)\t16.777438519048328\n",
      "  (2, 7971)\t5.95022462954512\n",
      "  (2, 7522)\t4.118789105665062\n",
      "  (2, 7343)\t29.53240197830258\n",
      "  (2, 7198)\t2.6702044427649785\n",
      "  (2, 6858)\t19.30407686030629\n",
      "  :\t:\n",
      "  (5568, 3397)\t4.8856811909483655\n",
      "  (5568, 3200)\t29.61367231494946\n",
      "  (5568, 2859)\t52.025039687012416\n",
      "  (5569, 7224)\t5.496461146316655\n",
      "  (5569, 6987)\t74.65252962559933\n",
      "  (5569, 6673)\t13.077156776862903\n",
      "  (5569, 5583)\t74.65252962559933\n",
      "  (5569, 4880)\t27.52002871311338\n",
      "  (5569, 1089)\t32.26552404195017\n",
      "  (5570, 7881)\t5.705508282094282\n",
      "  (5570, 7651)\t7.431607390021632\n",
      "  (5570, 6698)\t8.312534036669595\n",
      "  (5570, 5075)\t7.795662564800782\n",
      "  (5570, 4407)\t3.6147686296861807\n",
      "  (5570, 3976)\t22.174492603266945\n",
      "  (5570, 3530)\t7.625021875739395\n",
      "  (5570, 3318)\t20.40765057996318\n",
      "  (5570, 3213)\t4.059688350940881\n",
      "  (5570, 2773)\t16.863607629495327\n",
      "  (5570, 1743)\t6.3440034422351985\n",
      "  (5570, 1524)\t21.436037080857655\n",
      "  (5570, 908)\t33.928187106227604\n",
      "  (5571, 7477)\t23.090548460735015\n",
      "  (5571, 6177)\t58.00625725772179\n",
      "  (5571, 4989)\t18.40428065338335\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(with_mean = False)\n",
    "scaler.fit(X)\n",
    "standardized_data = scaler.transform(X)\n",
    "print(standardized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d519ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8050)\t10.610294654784285\n",
      "  (0, 7842)\t3.8773009678473875\n",
      "  (0, 5648)\t11.786587357750989\n",
      "  (0, 4277)\t20.196702346052152\n",
      "  (0, 4160)\t74.65252962559933\n",
      "  (0, 3480)\t4.384491807051848\n",
      "  (0, 3442)\t3.2345142595031966\n",
      "  (0, 3397)\t2.324027425051536\n",
      "  (0, 2250)\t32.20026757080644\n",
      "  (0, 1990)\t28.707498530069987\n",
      "  (0, 1713)\t24.380954375790882\n",
      "  (0, 1711)\t37.422578295735015\n",
      "  (0, 1293)\t15.002187984133633\n",
      "  (0, 1066)\t74.65252962559933\n",
      "  (1, 7959)\t18.37311842570421\n",
      "  (1, 5275)\t44.52172833850037\n",
      "  (1, 5245)\t3.0468679928408937\n",
      "  (1, 4314)\t14.129169916144727\n",
      "  (1, 4124)\t33.69351581745086\n",
      "  (2, 8009)\t16.777438519048328\n",
      "  (2, 7971)\t5.95022462954512\n",
      "  (2, 7522)\t4.118789105665062\n",
      "  (2, 7343)\t29.53240197830258\n",
      "  (2, 7198)\t2.6702044427649785\n",
      "  (2, 6858)\t19.30407686030629\n",
      "  :\t:\n",
      "  (5568, 3397)\t4.8856811909483655\n",
      "  (5568, 3200)\t29.61367231494946\n",
      "  (5568, 2859)\t52.025039687012416\n",
      "  (5569, 7224)\t5.496461146316655\n",
      "  (5569, 6987)\t74.65252962559933\n",
      "  (5569, 6673)\t13.077156776862903\n",
      "  (5569, 5583)\t74.65252962559933\n",
      "  (5569, 4880)\t27.52002871311338\n",
      "  (5569, 1089)\t32.26552404195017\n",
      "  (5570, 7881)\t5.705508282094282\n",
      "  (5570, 7651)\t7.431607390021632\n",
      "  (5570, 6698)\t8.312534036669595\n",
      "  (5570, 5075)\t7.795662564800782\n",
      "  (5570, 4407)\t3.6147686296861807\n",
      "  (5570, 3976)\t22.174492603266945\n",
      "  (5570, 3530)\t7.625021875739395\n",
      "  (5570, 3318)\t20.40765057996318\n",
      "  (5570, 3213)\t4.059688350940881\n",
      "  (5570, 2773)\t16.863607629495327\n",
      "  (5570, 1743)\t6.3440034422351985\n",
      "  (5570, 1524)\t21.436037080857655\n",
      "  (5570, 908)\t33.928187106227604\n",
      "  (5571, 7477)\t23.090548460735015\n",
      "  (5571, 6177)\t58.00625725772179\n",
      "  (5571, 4989)\t18.40428065338335 [0 0 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X = standardized_data\n",
    "Y = spam_data['Category'].values\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44975670",
   "metadata": {},
   "source": [
    "##### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c36a01a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8217) (4457, 8217) (1115, 8217)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = .2, stratify = Y)\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e893d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbd3701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 20 is smaller than n_iter=30. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 18 is smaller than n_iter=30. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zooby\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Parameters (Fine Search): {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "XGBoost Best Parameters (Fine Search): {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
      "SVM Best Parameters (Fine Search): {'C': 0.010000000000000002, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Best Model Train Accuracy (Fine Search): 0.991249719542293\n",
      "Best Model Test Accuracy (Fine Search): 0.9757847533632287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Define parameter grids for randomized search (coarse search)\n",
    "logistic_param_grid_coarse = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "xgboost_param_grid_coarse = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "svm_param_grid_coarse = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for each model (coarse search)\n",
    "logistic_random_search_coarse = RandomizedSearchCV(LogisticRegression(), logistic_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "xgboost_random_search_coarse = RandomizedSearchCV(XGBClassifier(objective='binary:logistic'), xgboost_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "svm_random_search_coarse = RandomizedSearchCV(svm.SVC(), svm_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using RandomizedSearchCV (coarse search)\n",
    "logistic_random_search_coarse.fit(X_train, Y_train)\n",
    "xgboost_random_search_coarse.fit(X_train, Y_train)\n",
    "svm_random_search_coarse.fit(X_train, Y_train)\n",
    "\n",
    "# Get best hyperparameters from RandomizedSearchCV (coarse search)\n",
    "best_logistic_params_coarse = logistic_random_search_coarse.best_params_\n",
    "best_xgboost_params_coarse = xgboost_random_search_coarse.best_params_\n",
    "best_svm_params_coarse = svm_random_search_coarse.best_params_\n",
    "\n",
    "# Define parameter grids for GridSearchCV (fine search)\n",
    "logistic_param_grid_fine = {\n",
    "    'penalty': [best_logistic_params_coarse['penalty']],\n",
    "    'C': [best_logistic_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'solver': [best_logistic_params_coarse['solver']]\n",
    "}\n",
    "\n",
    "xgboost_param_grid_fine = {\n",
    "    'learning_rate': [best_xgboost_params_coarse['learning_rate'] * i for i in [0.5, 1, 2]],\n",
    "    'n_estimators': [best_xgboost_params_coarse['n_estimators']],\n",
    "    'max_depth': [best_xgboost_params_coarse['max_depth']],\n",
    "    'min_child_weight': [best_xgboost_params_coarse['min_child_weight']],\n",
    "    'subsample': [best_xgboost_params_coarse['subsample']],\n",
    "    'colsample_bytree': [best_xgboost_params_coarse['colsample_bytree']]\n",
    "}\n",
    "\n",
    "svm_param_grid_fine = {\n",
    "    'C': [best_svm_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'gamma': [best_svm_params_coarse['gamma'] * i for i in [0.1, 1, 10]],\n",
    "    'kernel': [best_svm_params_coarse['kernel']]\n",
    "}\n",
    "\n",
    "# GridSearchCV for each model (fine search)\n",
    "logistic_grid_search_fine = GridSearchCV(LogisticRegression(), param_grid=logistic_param_grid_fine, cv=5, n_jobs=-1)\n",
    "xgboost_grid_search_fine = GridSearchCV(XGBClassifier(objective='binary:logistic'), param_grid=xgboost_param_grid_fine, cv=5, n_jobs=-1)\n",
    "svm_grid_search_fine = GridSearchCV(svm.SVC(), param_grid=svm_param_grid_fine, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using GridSearchCV (fine search)\n",
    "logistic_grid_search_fine.fit(X_train, Y_train)\n",
    "xgboost_grid_search_fine.fit(X_train, Y_train)\n",
    "svm_grid_search_fine.fit(X_train, Y_train)\n",
    "\n",
    "# Print best hyperparameters from GridSearchCV (fine search)\n",
    "print(\"Logistic Regression Best Parameters (Fine Search):\", logistic_grid_search_fine.best_params_)\n",
    "print(\"XGBoost Best Parameters (Fine Search):\", xgboost_grid_search_fine.best_params_)\n",
    "print(\"SVM Best Parameters (Fine Search):\", svm_grid_search_fine.best_params_)\n",
    "\n",
    "# Compare cross-validated scores of each model\n",
    "logistic_cv_score_fine = logistic_grid_search_fine.best_score_\n",
    "xgboost_cv_score_fine = xgboost_grid_search_fine.best_score_\n",
    "svm_cv_score_fine = svm_grid_search_fine.best_score_\n",
    "\n",
    "# Select the best model based on cross-validated scores\n",
    "best_model_fine = None\n",
    "if logistic_cv_score_fine >= xgboost_cv_score_fine and logistic_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = logistic_grid_search_fine.best_estimator_\n",
    "elif xgboost_cv_score_fine >= logistic_cv_score_fine and xgboost_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = xgboost_grid_search_fine.best_estimator_\n",
    "else:\n",
    "    best_model_fine = svm_grid_search_fine.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_accuracy_fine = best_model_fine.score(X_train, Y_train)\n",
    "print(\"Best Model Train Accuracy (Fine Search):\", train_accuracy_fine)\n",
    "test_accuracy_fine = best_model_fine.score(X_test, Y_test)\n",
    "print(\"Best Model Test Accuracy (Fine Search):\", test_accuracy_fine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e9916b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9757847533632287\n",
      "Precision: 0.9765625\n",
      "Recall: 0.8389261744966443\n",
      "F1 Score: 0.9025270758122744\n",
      "ROC AUC Score: 0.9887378937568607\n",
      "Confusion Matrix:\n",
      "[[963   3]\n",
      " [ 24 125]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_fine.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "precision = precision_score(Y_test, y_pred)\n",
    "recall = recall_score(Y_test, y_pred)\n",
    "f1 = f1_score(Y_test, y_pred)\n",
    "roc_auc = roc_auc_score(Y_test, best_model_fine.predict_proba(X_test)[:, 1])\n",
    "conf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ab72ec",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb21656c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier()\n",
    "random_forest_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2c58f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97847533632287\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score\n",
    "X_test_prediction = random_forest_classifier.predict(X_test)\n",
    "test_data_accuracy_random_forest = accuracy_score(X_test_prediction, Y_test)\n",
    "print('Accuracy:', test_data_accuracy_random_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf689017",
   "metadata": {},
   "source": [
    "##### Making a predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "877519c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Spam\n"
     ]
    }
   ],
   "source": [
    "input_data = [\"Your free ringtone is waiting to be collected. Simply text the password \"\"MIX\"\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16\"]\n",
    "\n",
    "input_data_features = vectorizer.transform(input_data) #you use the vectorizer to transform the data based on the vectorizer you created earlier\n",
    "\n",
    "\n",
    "prediction = best_model_fine.predict(input_data_features)\n",
    "print(prediction)\n",
    "if prediction == 0:\n",
    "    print(\"Not Spam\")\n",
    "else:\n",
    "    print(\"Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff0e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
