{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3bda675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: unique id for a news article\\ntitle: the title of a news article\\nauthor: author of the news article\\ntext: the text of the article; could be incomplete\\nlabel: a label that marks the article as potentially unreliable: 1 = fake news and 0 = real news\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: unique id for a news article\n",
    "title: the title of a news article\n",
    "author: author of the news article\n",
    "text: the text of the article; could be incomplete\n",
    "label: a label that marks the article as potentially unreliable: 1 = fake news and 0 = real news\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d084f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e56f71b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import nltk\\nnltk.download('stopwords')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import nltk\n",
    "nltk.download('stopwords')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ce6bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd5584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610b6caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce34210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ab8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with empty string - usually you dont drop null values but this is a large dataset so we can still train model\n",
    "news_dataset = news_dataset.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29010c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d40ebdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the author name and title columns - later on add the text column too to see what happens\n",
    "news_dataset['content'] = news_dataset['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "149568ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title           author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...    Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  Daniel J. Flynn   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1   \n",
       "1  Ever get the feeling your life circles the rou...      0   \n",
       "\n",
       "                                             content  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  Ever get the feeling your life circles the rou...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73103bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating content and label columns\n",
    "X = news_dataset.drop(columns = 'label', axis = 1)\n",
    "Y = news_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9e57e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              title  \\\n",
      "0          0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
      "2          2                  Why the Truth Might Get You Fired   \n",
      "3          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
      "4          4  Iranian woman jailed for fictional unpublished...   \n",
      "...      ...                                                ...   \n",
      "20795  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
      "20796  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
      "20797  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
      "20798  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
      "20799  20799                          What Keeps the F-35 Alive   \n",
      "\n",
      "                                          author  \\\n",
      "0                                  Darrell Lucus   \n",
      "1                                Daniel J. Flynn   \n",
      "2                             Consortiumnews.com   \n",
      "3                                Jessica Purkiss   \n",
      "4                                 Howard Portnoy   \n",
      "...                                          ...   \n",
      "20795                              Jerome Hudson   \n",
      "20796                           Benjamin Hoffman   \n",
      "20797  Michael J. de la Merced and Rachel Abrams   \n",
      "20798                                Alex Ansary   \n",
      "20799                              David Swanson   \n",
      "\n",
      "                                                    text  \\\n",
      "0      House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
      "1      Ever get the feeling your life circles the rou...   \n",
      "2      Why the Truth Might Get You Fired October 29, ...   \n",
      "3      Videos 15 Civilians Killed In Single US Airstr...   \n",
      "4      Print \\nAn Iranian woman has been sentenced to...   \n",
      "...                                                  ...   \n",
      "20795  Rapper T. I. unloaded on black celebrities who...   \n",
      "20796  When the Green Bay Packers lost to the Washing...   \n",
      "20797  The Macy’s of today grew from the union of sev...   \n",
      "20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
      "20799    David Swanson is an author, activist, journa...   \n",
      "\n",
      "                                                 content  \n",
      "0      House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
      "1      Ever get the feeling your life circles the rou...  \n",
      "2      Why the Truth Might Get You Fired October 29, ...  \n",
      "3      Videos 15 Civilians Killed In Single US Airstr...  \n",
      "4      Print \\nAn Iranian woman has been sentenced to...  \n",
      "...                                                  ...  \n",
      "20795  Rapper T. I. unloaded on black celebrities who...  \n",
      "20796  When the Green Bay Packers lost to the Washing...  \n",
      "20797  The Macy’s of today grew from the union of sev...  \n",
      "20798  NATO, Russia To Hold Parallel Exercises In Bal...  \n",
      "20799    David Swanson is an author, activist, journa...  \n",
      "\n",
      "[20800 rows x 5 columns] 0        1\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "20795    0\n",
      "20796    0\n",
      "20797    0\n",
      "20798    1\n",
      "20799    1\n",
      "Name: label, Length: 20800, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb4ac9",
   "metadata": {},
   "source": [
    "###### Stemming:\n",
    "    \n",
    "Stemming is the process of reducing a word to its root word\n",
    "\n",
    "example:\n",
    "actor, actress, acting --> will get turned to act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "557bfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84159d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content) #this regex is looking for words from a-z only. no numbers. commas and fullstops are replaced with a space as indicated by ' '\n",
    "    stemmed_content = stemmed_content.lower()#convert everything to lowercase letters\n",
    "    stemmed_content = stemmed_content.split()#convert everything in content to a list\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #reducing words to their root word - but for loop is removing all stop words\n",
    "    stemmed_content = ' '.join(stemmed_content)#joining all words\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['content'] = news_dataset['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3423de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_dataset['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating data and label - youre not dropping the label column here bc the only thing youre doing is comparing it to content\n",
    "#you would drop the label to make it easier to seperate the data if you were comparing label to multiple columns\n",
    "X = news_dataset['content'].values\n",
    "Y = news_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac2d6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting text data to numbers\n",
    "#main point of vectorizer is that it will create feature columns that it deems is important\n",
    "vectorizer = TfidfVectorizer() #basically finds words that are repeating the most to assign a value to it. similarly its inversely doing the opposite where if certain words are showing up and it doesnt have a value, it doesnt provide it value\n",
    "vectorizer.fit(X) #only fitting X bc Y already is all numbers (0,1)\n",
    "\n",
    "X = vectorizer.transform(X) #convert all values to respective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60032793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f41d7",
   "metadata": {},
   "source": [
    "Splitting data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa734d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = .2, stratify = Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85fbe28",
   "metadata": {},
   "source": [
    "###### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Define parameter grids for randomized search (coarse search)\n",
    "logistic_param_grid_coarse = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "xgboost_param_grid_coarse = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "svm_param_grid_coarse = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV for each model (coarse search)\n",
    "logistic_random_search_coarse = RandomizedSearchCV(LogisticRegression(), logistic_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "xgboost_random_search_coarse = RandomizedSearchCV(XGBClassifier(objective='binary:logistic'), xgboost_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "svm_random_search_coarse = RandomizedSearchCV(svm.SVC(), svm_param_grid_coarse, n_iter=30, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using RandomizedSearchCV (coarse search)\n",
    "logistic_random_search_coarse.fit(X_train, Y_train)\n",
    "xgboost_random_search_coarse.fit(X_train, Y_train)\n",
    "svm_random_search_coarse.fit(X_train, Y_train)\n",
    "\n",
    "# Get best hyperparameters from RandomizedSearchCV (coarse search)\n",
    "best_logistic_params_coarse = logistic_random_search_coarse.best_params_\n",
    "best_xgboost_params_coarse = xgboost_random_search_coarse.best_params_\n",
    "best_svm_params_coarse = svm_random_search_coarse.best_params_\n",
    "\n",
    "# Define parameter grids for GridSearchCV (fine search)\n",
    "logistic_param_grid_fine = {\n",
    "    'penalty': [best_logistic_params_coarse['penalty']],\n",
    "    'C': [best_logistic_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'solver': [best_logistic_params_coarse['solver']]\n",
    "}\n",
    "\n",
    "xgboost_param_grid_fine = {\n",
    "    'learning_rate': [best_xgboost_params_coarse['learning_rate'] * i for i in [0.5, 1, 2]],\n",
    "    'n_estimators': [best_xgboost_params_coarse['n_estimators']],\n",
    "    'max_depth': [best_xgboost_params_coarse['max_depth']],\n",
    "    'min_child_weight': [best_xgboost_params_coarse['min_child_weight']],\n",
    "    'subsample': [best_xgboost_params_coarse['subsample']],\n",
    "    'colsample_bytree': [best_xgboost_params_coarse['colsample_bytree']]\n",
    "}\n",
    "\n",
    "svm_param_grid_fine = {\n",
    "    'C': [best_svm_params_coarse['C'] * i for i in [0.1, 1, 10]],\n",
    "    'gamma': [best_svm_params_coarse['gamma'] * i for i in [0.1, 1, 10]],\n",
    "    'kernel': [best_svm_params_coarse['kernel']]\n",
    "}\n",
    "\n",
    "# GridSearchCV for each model (fine search)\n",
    "logistic_grid_search_fine = GridSearchCV(LogisticRegression(), param_grid=logistic_param_grid_fine, cv=5, n_jobs=-1)\n",
    "xgboost_grid_search_fine = GridSearchCV(XGBClassifier(objective='binary:logistic'), param_grid=xgboost_param_grid_fine, cv=5, n_jobs=-1)\n",
    "svm_grid_search_fine = GridSearchCV(svm.SVC(), param_grid=svm_param_grid_fine, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit models using GridSearchCV (fine search)\n",
    "logistic_grid_search_fine.fit(X_train, Y_train)\n",
    "xgboost_grid_search_fine.fit(X_train, Y_train)\n",
    "svm_grid_search_fine.fit(X_train, Y_train)\n",
    "\n",
    "# Print best hyperparameters from GridSearchCV (fine search)\n",
    "print(\"Logistic Regression Best Parameters (Fine Search):\", logistic_grid_search_fine.best_params_)\n",
    "print(\"XGBoost Best Parameters (Fine Search):\", xgboost_grid_search_fine.best_params_)\n",
    "print(\"SVM Best Parameters (Fine Search):\", svm_grid_search_fine.best_params_)\n",
    "\n",
    "# Compare cross-validated scores of each model\n",
    "logistic_cv_score_fine = logistic_grid_search_fine.best_score_\n",
    "xgboost_cv_score_fine = xgboost_grid_search_fine.best_score_\n",
    "svm_cv_score_fine = svm_grid_search_fine.best_score_\n",
    "\n",
    "# Select the best model based on cross-validated scores\n",
    "best_model_fine = None\n",
    "if logistic_cv_score_fine >= xgboost_cv_score_fine and logistic_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = logistic_grid_search_fine.best_estimator_\n",
    "elif xgboost_cv_score_fine >= logistic_cv_score_fine and xgboost_cv_score_fine >= svm_cv_score_fine:\n",
    "    best_model_fine = xgboost_grid_search_fine.best_estimator_\n",
    "else:\n",
    "    best_model_fine = svm_grid_search_fine.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "train_accuracy_fine = best_model_fine.score(X_train, Y_train)\n",
    "print(\"Best Model Train Accuracy (Fine Search):\", train_accuracy_fine)\n",
    "test_accuracy_fine = best_model_fine.score(X_test, Y_test)\n",
    "print(\"Best Model Test Accuracy (Fine Search):\", test_accuracy_fine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1fb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6171e7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_fine.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model_fine, 'text_only.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d4f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac38449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316076c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3a25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73c43659",
   "metadata": {},
   "source": [
    "Training model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a95b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd3137",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3cfa95",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62650a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_prediction = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score of the training data:\", training_data_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_prediction = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy score of the test data: ', test_data_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2518d7",
   "metadata": {},
   "source": [
    "Make a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97221906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 132672)\n",
      "[0]\n",
      "This is real news\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[70]\n",
    "print(X_new.shape)\n",
    "\n",
    "\n",
    "prediction = best_model_fine.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('This is real news')\n",
    "else:\n",
    "    print('This is fake news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "104bf017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print (Y_test[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a48db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
